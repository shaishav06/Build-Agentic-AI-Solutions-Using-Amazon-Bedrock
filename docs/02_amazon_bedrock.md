# ğŸŒ Understanding Amazon Bedrock

## ğŸ—ï¸ Overview
Amazon Bedrock is a **fully managed service** that provides access to **pre-trained foundation models (FMs)** from leading AI providers. It enables developers to build and deploy **Agentic AI** applications **without managing infrastructure**. ğŸš€

![ğŸ› ï¸ Bedrock](../images/bedrockdesh.png)

### ğŸ”¹ Key Foundation Models Available in Amazon Bedrock
Amazon Bedrock provides access to several **pre-trained models**, including:

| ğŸ¤– Model Name | ğŸ¢ Provider | ğŸ¯ Best For |
|------------|-----------|-------------|
| **Amazon Titan** | AWS | General-purpose AI tasks, embeddings, text generation |
| **Claude** | Anthropic | Conversational AI, reasoning, and summarization |
| **Jurassic-2** | AI21 Labs | Long-form text generation, writing assistance |
| **Stable Diffusion** | Stability AI | Image generation and editing |

### ğŸ”¹ âš¡ API-Based Inference
With Amazon Bedrock, developers can interact with foundation models **via APIs**, eliminating the need to provision GPUs or infrastructure. ğŸ’¡

#### ğŸ“Œ Example: Calling Amazon Bedrock API with Python (Boto3)
```python
import boto3
import json

# Initialize Bedrock client
client = boto3.client('bedrock-runtime')

# Define input prompt
prompt = "Summarize the latest AI trends in 2024."

# Invoke model (Claude in this case)
response = client.invoke_model(
    modelId='anthropic.claude-v1',
    body=json.dumps({"prompt": prompt, "max_tokens": 200})
)

# Parse and print response
result = json.loads(response['body'].read())
print(result['completion'])
```
ğŸ› ï¸ This API call sends a **text prompt** to the Claude model and returns a summarized response.

---

## ğŸ”‘ Key Features

### 1ï¸âƒ£ **â˜ï¸ Serverless Deployment**
- Amazon Bedrock abstracts infrastructure management, allowing developers to **focus on AI logic** rather than scaling concerns.
- âœ… **Auto-scales** based on API requests.
- ğŸ› ï¸ **No need to manage GPUs or clusters**.

#### ğŸ“Œ Example: Deploying an AI-powered FAQ Bot
1. ğŸ“¡ **Create an API Gateway** to accept user queries.
2. âš¡ **Use AWS Lambda** to invoke Amazon Bedrock models.
3. ğŸ“© **Return AI-generated responses** to the user.

---

### 2ï¸âƒ£ **ğŸ› ï¸ Fine-Tuning & Retrieval-Augmented Generation (RAG)**
- Developers can **fine-tune models** with domain-specific datasets.
- **RAG** enhances AI memory by integrating external data sources (e.g., **Amazon OpenSearch** for vector search). ğŸ”

#### ğŸ“Œ Example: Fine-Tuning Amazon Titan with Custom Data
1. ğŸ“‚ Prepare **training data** in Amazon S3.
2. ğŸ¯ Use **AWS SageMaker** to fine-tune the model.
3. ğŸš€ Deploy the fine-tuned model via **Amazon Bedrock** for inference.

---

### 3ï¸âƒ£ **ğŸ”— Seamless AWS Integration**
Amazon Bedrock is deeply integrated with AWS services:
- ğŸ—„ï¸ **Amazon S3** â†’ Store AI training data.
- âš™ï¸ **AWS Lambda** â†’ Automate AI workflows.
- ğŸ” **Amazon OpenSearch** â†’ Power **Retrieval-Augmented Generation (RAG)**.
- ğŸ“Š **Amazon DynamoDB** â†’ Store structured AI responses.

#### ğŸ“Œ Example: AI-Powered Document Search with RAG
1. ğŸ“ **Upload documents** to **Amazon S3**.
2. ğŸ§  **Extract embeddings** using **Amazon Titan**.
3. ğŸ“Œ **Store embeddings** in **Amazon OpenSearch**.
4. ğŸ”„ **Query OpenSearch** to retrieve context and generate responses using Bedrock models.

---
### ğŸ¯ ğŸš€ Next Steps:
Proceed to **[Core Components of Agentic AI](./03_core_components.md)** to explore AI orchestration and automation. ğŸ”¥